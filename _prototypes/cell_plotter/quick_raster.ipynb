{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import tkinter as tk\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from math import ceil\n",
    "import cv2\n",
    "import ot as pot\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "PROJECT_PATH = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "# PROJECT_PATH = os.getcwd()\n",
    "sys.path.append(os.path.dirname(PROJECT_PATH))\n",
    "\n",
    "from _prototypes.cell_remapping.src.remapping import pot_sliced_wasserstein\n",
    "from _prototypes.cell_remapping.src.wasserstein_distance import _get_ratemap_bucket_midpoints, single_point_wasserstein\n",
    "\n",
    "unit_matcher_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(unit_matcher_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "print(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _prototypes.cell_remapping.main import main\n",
    "from _prototypes.cell_remapping.src.settings import settings_dict\n",
    "from x_io.rw.axona.batch_read import make_study\n",
    "from library.study_space import Animal\n",
    "\n",
    "settings_dict['useMatchedCut'] = False\n",
    "settings_dict['ppm'] = 711\n",
    "\n",
    "studies = []\n",
    "failed = []\n",
    "path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\all\"\n",
    "animal_pos_dict = {}\n",
    "for folder in os.listdir(path):\n",
    "    newp = os.path.join(path,folder)\n",
    "    if 'sub' not in folder:\n",
    "        # and 'Session3' in folder:\n",
    "        study = make_study(newp,settings_dict=settings_dict)\n",
    "        study.make_animals()\n",
    "        for animal in study.animals:\n",
    "            pos_fp = newp + r\"\\position.txt\"\n",
    "            pos_data = pd.read_csv(pos_fp, sep='\\t', header=None)\n",
    "            # print(len(pos_data))\n",
    "            # split each line at the comma\n",
    "            pos_data = pos_data[0].str.split(';', expand=True)  \n",
    "            # drop wherever there is the word 'POSITION'\n",
    "            pos_data = pos_data[~pos_data[0].str.contains('POSITION')]\n",
    "            \n",
    "            # drop(pos_data[pos_data[0] == 'POSITION'].index)\n",
    "            # pos_data = pos_data[1:]\n",
    "            # rename columns\n",
    "            pos_data.columns = ['time', 'x', 'y']\n",
    "            # convert to numeric\n",
    "            pos_data = pos_data.apply(pd.to_numeric)\n",
    "            animal_pos_dict[animal.animal_id] = pos_data\n",
    "\n",
    "        studies.append(study)\n",
    "    else:\n",
    "        failed.append(newp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = []\n",
    "spike_dict = {}\n",
    "ses_cts = []\n",
    "ses_names = {}\n",
    "ses_ct = 1\n",
    "for study in studies:\n",
    "    for animal in study.animals:\n",
    "        cells = animal.sessions['session_1'].get_cell_data()['cell_ensemble'].cells\n",
    "        spike_dict[animal.animal_id] = cells\n",
    "\n",
    "\n",
    "        for cell in cells:\n",
    "            spikes.append(cell.event_times)\n",
    "            ses_cts.append(ses_ct)\n",
    "            ses_names[ses_ct] = animal.animal_id\n",
    "\n",
    "    ses_ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_names = []\n",
    "for ky in animal_pos_dict.keys():\n",
    "    nme = ky.split('_tet')[0]\n",
    "    if nme not in unq_names:\n",
    "        unq_names.append(nme)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 40))\n",
    "ct = 1\n",
    "for ky in unq_names:\n",
    "    dta = animal_pos_dict[ky + '_tet1']\n",
    "    ax1 = fig.add_subplot(len(unq_names), 2, ct)\n",
    "    ax1.plot(dta['time'], dta['x'])\n",
    "    ax1.set_title(ky + ' - X vs Time')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('X')\n",
    "\n",
    "    ax2 = fig.add_subplot(len(unq_names), 2, ct + 1)\n",
    "    ax2.plot(dta['x'])\n",
    "    ax2.set_title(ky + ' - X vs index')\n",
    "    ax2.set_xlabel('Index')\n",
    "    ax2.set_ylabel('X')\n",
    "\n",
    "    ct += 2\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_chunks = {}\n",
    "\n",
    "unq_names = []\n",
    "for ky in animal_pos_dict.keys():\n",
    "    nme = ky.split('_tet')[0]\n",
    "    if nme not in unq_names:\n",
    "        unq_names.append(nme)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "ct = 1\n",
    "\n",
    "for ky in unq_names:\n",
    "    dta = animal_pos_dict[ky + '_tet1']\n",
    "    total_positions = max(dta['x']) \n",
    "    chunk_size = 128  # Chunk size in units of position\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = int(total_positions / chunk_size) + 1\n",
    "    \n",
    "    combined_chunk_x = []\n",
    "    combined_chunk_time = []\n",
    "    combined_chunk_index = []\n",
    "    \n",
    "    for chunk_index in range(num_chunks):\n",
    "        start_pos = chunk_index * chunk_size\n",
    "        end_pos = (chunk_index + 1) * chunk_size\n",
    "        # print(start_pos, end_pos)\n",
    "        \n",
    "        # Find corresponding indices for start and end positions\n",
    "        # start_idx = next((idx for idx, pos in enumerate(dta['x']) if pos >= start_pos), None)\n",
    "        # end_idx = next((idx for idx, pos in enumerate(dta['x']) if pos > end_pos), None)  # Exclusive end\n",
    "        start_idx = np.where(dta['x'] >= start_pos)[0][0]\n",
    "        end_idx = np.where(dta['x'] > end_pos)[0]\n",
    "        if len(end_idx) > 0:\n",
    "            end_idx = end_idx[0]\n",
    "        else:\n",
    "            end_idx = None\n",
    "        # end_idx = end_idx if end_idx is not None else len(dta['x'])\n",
    "        \n",
    "        chunk_time = dta['time'][start_idx:end_idx].to_numpy()\n",
    "        chunk_x = dta['x'][start_idx:end_idx].to_numpy()\n",
    "        if len(chunk_x) > 0:\n",
    "            chunk_x = chunk_x - chunk_x[0]\n",
    "\n",
    "            if np.min(chunk_x) >= 0 and np.max(chunk_x) <= 128 and chunk_x[-1] - chunk_x[0] > 50:\n",
    "\n",
    "                valid_chunks[ky + '_chunk_' + str(chunk_index)] = {}\n",
    "                valid_chunks[ky + '_chunk_' + str(chunk_index)]['chunk_x'] = chunk_x\n",
    "                valid_chunks[ky + '_chunk_' + str(chunk_index)]['chunk_time'] = chunk_time\n",
    "                \n",
    "\n",
    "        combined_chunk_x.extend(chunk_x)\n",
    "        combined_chunk_time.extend(chunk_time)\n",
    "        # stp = (end_pos - start_pos) / len(chunk_x)\n",
    "        # combined_chunk_index.extend(np.arange(start_pos, end_pos, stp))\n",
    "    \n",
    "    ax1 = fig.add_subplot(len(unq_names), 2, ct)\n",
    "    ax1.plot(combined_chunk_time, combined_chunk_x)\n",
    "    ax1.set_title(f\"{ky} - X vs Time\")\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('X')\n",
    "    # ax1.set_ylim([0, 128])\n",
    "\n",
    "    ax2 = fig.add_subplot(len(unq_names), 2, ct + 1)\n",
    "    ax2.plot(range(len(combined_chunk_x)), combined_chunk_x)\n",
    "    ax2.set_title(f\"{ky} - X vs Index\")\n",
    "    ax2.set_xlabel('Index')\n",
    "    ax2.set_ylabel('X')\n",
    "    # ax2.set_ylim([0, 128])\n",
    "\n",
    "    ct += 2\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _speed1D(x, t, window_sizes=np.arange(1, 100, 2)):\n",
    "    \"\"\"Calculates smoothed speed using multiple window sizes and averages the results\"\"\"\n",
    "    N = len(x)\n",
    "    v_smoothed = np.zeros(N)\n",
    "\n",
    "    for index in range(N):\n",
    "        speeds = []\n",
    "        for window_size in window_sizes:\n",
    "            start_index = max(0, index - window_size // 2)\n",
    "            end_index = min(N - 1, index + window_size // 2)\n",
    "\n",
    "            dx = x[end_index] - x[start_index]\n",
    "            dt = t[end_index] - t[start_index]\n",
    "\n",
    "            if dt != 0:\n",
    "                speed = np.abs(dx / dt)\n",
    "                speeds.append(speed)\n",
    "\n",
    "        if speeds:\n",
    "            v_smoothed[index] = np.mean(speeds)\n",
    "        else:\n",
    "            v_smoothed[index] = 0  # Set speed to 0 if no valid speeds are computed\n",
    "\n",
    "    return v_smoothed\n",
    "\n",
    "\n",
    "\n",
    "def _gkern(kernlen: int, std: int) -> np.ndarray:\n",
    "\n",
    "    '''\n",
    "        Returns a 2D Gaussian kernel array.\n",
    "\n",
    "        Params:\n",
    "            kernlen, std (int):\n",
    "                Kernel length and standard deviation\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray:\n",
    "                gkern2d\n",
    "    '''\n",
    "\n",
    "    gkern1d = signal.gaussian(kernlen, std=std).reshape(kernlen, 1)\n",
    "    gkern2d = np.outer(gkern1d, gkern1d)\n",
    "    return gkern2d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "animal_ids = []\n",
    "for ky in valid_chunks.keys():\n",
    "    animal_ids.append(ky.split('_chunk')[0])\n",
    "animal_ids = np.unique(animal_ids)\n",
    "\n",
    "avg_chunks = {}\n",
    "\n",
    "for unq_animal in animal_ids:\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    axt = ax.twinx()\n",
    "    ky_c = {}\n",
    "    # chunks\n",
    "    for ky in valid_chunks.keys():\n",
    "        if unq_animal in ky:\n",
    "            spk_keys = list(spike_dict.keys())\n",
    "            spk_keys = [x for x in spk_keys if ky.split('_chunk')[0] in x]\n",
    "            \n",
    "            if unq_animal not in avg_chunks:\n",
    "                avg_chunks[unq_animal] = {}\n",
    "\n",
    "            ky_c[ky] = 1\n",
    "            # tetrodes\n",
    "            for spk_ky in spk_keys:\n",
    "                spk_data = spike_dict[spk_ky]\n",
    "                # cells \n",
    "                for cell in spk_data:\n",
    "                    tet_cell_id = str(spk_ky.split('_tet')[-1]) + '_' + str(cell.cluster.cluster_label)\n",
    "                    spks_to_plot = cell.event_times\n",
    "                    spks_to_plot = spks_to_plot[spks_to_plot >= valid_chunks[ky]['chunk_time'][0]]\n",
    "                    spks_to_plot = spks_to_plot[spks_to_plot <= valid_chunks[ky]['chunk_time'][-1]]\n",
    "\n",
    "                    position_bins = np.arange(0, 129, 129/64)\n",
    "                    pos_bin_ct = np.zeros((64))\n",
    "                    for spk in spks_to_plot:\n",
    "                        closest_chunk_time = valid_chunks[ky]['chunk_time'][np.argmin(np.abs(valid_chunks[ky]['chunk_time'] - spk))]\n",
    "                        closest_chunk_idx = np.where(valid_chunks[ky]['chunk_time'] == closest_chunk_time)[0][0]\n",
    "                        closest_chunk_position = valid_chunks[ky]['chunk_x'][closest_chunk_idx]\n",
    "                        closest_position_bin = position_bins[np.argmin(np.abs(position_bins - closest_chunk_position))]\n",
    "                        closest_position_bin_idx = np.argmin(np.abs(position_bins - closest_chunk_position))\n",
    "                        pos_bin_ct[closest_position_bin_idx] += 1\n",
    "\n",
    "                    column_values = np.linspace(0,129,64)\n",
    "                    occ_map_raw = np.zeros((64))\n",
    "                    for i in range(0,len(valid_chunks[ky]['chunk_time'])):\n",
    "                        column_index = np.abs(column_values - valid_chunks[ky]['chunk_x'][i]).argmin()\n",
    "                        occ_map_raw[column_index] += valid_chunks[ky]['chunk_time'][i] - valid_chunks[ky]['chunk_time'][i-1]\n",
    "                        # kernlen = int(1*8)\n",
    "                        # std = int(0.2*kernlen)\n",
    "                        # occ_map_normalized = occ_map_raw / pos_t[-1]\n",
    "                        # occ_map_smoothed = cv2.filter2D(occ_map_normalized,-1,_gkern(kernlen,std))\n",
    "                        # kernel = np.ones((2,2))\n",
    "                        # occ_map_smoothed = occ_map_smoothed/max(occ_map_smoothed.flatten())\n",
    "\n",
    "                    # if len(spks_to_plot) != 0:\n",
    "                    #     # fr_map = pos_bin_ct / np.max(spks_to_plot)\n",
    "                    #     kernlen = int(3 * 8)\n",
    "                    #     std = int(0.2 * kernlen)\n",
    "                    #     fr_map = cv2.filter2D(fr_map, -1, _gkern(kernlen, std))\n",
    "                    #     fr_map = fr_map / np.max(fr_map)\n",
    "                    #     # fr_map = ndimage.gaussian_filter(fr_map, sigma=1)\n",
    "                    fr_map_raw = pos_bin_ct \n",
    "                    # / np.max(pos_bin_ct)\n",
    "\n",
    "                    # kernlen = int(1 * 8)\n",
    "                    # std = int(0.2 * kernlen)\n",
    "                    # pos_bin_ct = cv2.filter2D(pos_bin_ct, -1, _gkern(kernlen, std))\n",
    "                    # fr_map_smoothed = pos_bin_ct / np.max(pos_bin_ct)\n",
    "\n",
    "                    \n",
    "                    if tet_cell_id in avg_chunks[unq_animal].keys():\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['collection'] += fr_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['occ_map'] += occ_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['count'] += 1\n",
    "                        if valid_chunks[ky]['chunk_time'][-1] > avg_chunks[unq_animal][tet_cell_id]['T']:\n",
    "                            avg_chunks[unq_animal][tet_cell_id]['T'] = valid_chunks[ky]['chunk_time'][-1]\n",
    "                    else:\n",
    "                        avg_chunks[unq_animal][tet_cell_id] = {'collection': [], 'count': 0, 'occ_map': [], 'T':0}\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['occ_map'] = occ_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['collection'] = fr_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['count'] += 1\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['T'] = valid_chunks[ky]['chunk_time'][-1]\n",
    "                    \n",
    "\n",
    "                    # axt.plot(valid_chunks[ky]['chunk_time'], valid_chunks[ky]['chunk_x'], color='red', lw=0.5)\n",
    "                    t = valid_chunks[ky]['chunk_time']\n",
    "                    x = valid_chunks[ky]['chunk_x']\n",
    "                    speed = _speed1D(x, t)\n",
    "                    # convert_to_nan = np.where(speed > 20)[0]\n",
    "                    # convert_to_nan2 = np.where(speed < 10)[0]\n",
    "                    # convert_to_nan = np.concatenate((convert_to_nan, convert_to_nan2))\n",
    "                    # # convert_to_nan = []\n",
    "                    # # print(convert_to_nan)\n",
    "                    # # t[convert_to_nan] = np.nan\n",
    "                    # # t = t[(speed <30) & (speed > 0)]\n",
    "                    # # valid_spike_times = spks_to_plot[]\n",
    "                    # # speed = speed[(speed < 30) & (speed > 0)]\n",
    "                    # speed[convert_to_nan] = np.nan                 \n",
    "                    # smoothed_speed = ndimage.gaussian_filter(speed, sigma=100)\n",
    "                    \n",
    "                    if unq_animal == \"Mouse3_session11_230530_151933_2\":\n",
    "                        # t[speed > 20] = 0\n",
    "                        speed[speed > 7] = 0\n",
    "\n",
    "                    axt.plot(t, speed, color='red', lw=0.5, alpha=0.5)\n",
    "                    ax.plot(spks_to_plot, np.ones(len(spks_to_plot)) * ky_c[ky], 'ko', markersize=1)\n",
    "\n",
    "                    ky_c[ky] += 1\n",
    "\n",
    "    ax.set_title(unq_animal)\n",
    "    print(unq_animal)\n",
    "    ax.set_ylabel('Cell #')\n",
    "    axt.set_ylabel('Position')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.subplot(1,1,1)\n",
    "avg_map = []\n",
    "order = []\n",
    "for ky in avg_chunks.keys():\n",
    "    # if 'mouse3' in ky.lower():\n",
    "    for unit in avg_chunks[ky].keys():\n",
    "        avg = avg_chunks[ky][unit]['collection']\n",
    "        avg_occ_map = avg_chunks[ky][unit]['occ_map']\n",
    "        rate_map_raw = avg / avg_occ_map\n",
    "        T = avg_chunks[ky][unit]['T']\n",
    "        # order.append(np.sum(avg))\n",
    "        #  / avg_chunks[ky][unit]['count']\n",
    "        # avg = avg / np.sum(avg)\n",
    "        kernlen = int(1 * 8)\n",
    "        std = int(0.2 * kernlen)\n",
    "        avg = cv2.filter2D(avg, -1, _gkern(kernlen, std))\n",
    "        avg_occ_map = avg_occ_map / T\n",
    "        avg_occ_map = cv2.filter2D(avg_occ_map,-1,_gkern(kernlen,std))\n",
    "        avg = avg / np.max(avg)\n",
    "        avg_occ_map = avg_occ_map / np.max(avg_occ_map)\n",
    "        order.append(np.mean(avg))\n",
    "        rate_map = np.where(avg_occ_map<0.0001, 0, avg/avg_occ_map)\n",
    "        rate_map = rate_map/max(rate_map.flatten())\n",
    "        avg_map.append(rate_map)\n",
    "\n",
    "# order_idx = np.argsort(np.array(order))\n",
    "# avg_map = np.array(avg_map).squeeze()[order_idx,:]\n",
    "avg_map = np.asarray(avg_map).squeeze().T\n",
    "print(avg_map.shape)\n",
    "# map with colorbar\n",
    "img = ax.imshow(avg_map, aspect='auto', cmap='jet')\n",
    "ax.invert_yaxis()\n",
    "ax.set_yticklabels(np.arange(0, 80, 10))\n",
    "cbar = fig.colorbar(img, ax=ax)\n",
    "cbar.set_label('Firing Rate Norm')\n",
    "ax.set_xlabel('Cell #')\n",
    "ax.set_ylabel('Linear Track Length (cm)')\n",
    "# ax.set_title('Mouse 3')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = plt.subplot(1,1,1)\n",
    "avg_map = []\n",
    "for ky in avg_chunks.keys():\n",
    "    for unit in avg_chunks[ky].keys():\n",
    "        avg = avg_chunks[ky][unit]['collection'] \n",
    "        # avg = avg / np.max(avg)\n",
    "        avg_map.append(avg)\n",
    "\n",
    "# map with colorbar\n",
    "img = ax.imshow(avg_map, aspect='auto', cmap='jet')\n",
    "ax.invert_yaxis()\n",
    "# change yaxis to be from 0 to 79.9 instead of current\n",
    "ax.set_yticklabels(np.arange(0, 80, 10))\n",
    "cbar = fig.colorbar(img, ax=ax)\n",
    "cbar.set_label('Firing Rate Norm')\n",
    "ax.set_xlabel('Cell #')\n",
    "ax.set_ylabel('Linear Track Length (cm)')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "animal_ids = []\n",
    "for ky in valid_chunks.keys():\n",
    "    animal_ids.append(ky.split('_chunk')[0])\n",
    "animal_ids = np.unique(animal_ids)\n",
    "\n",
    "avg_chunks = {}\n",
    "unq_cell_plot_dict = {}\n",
    "\n",
    "for unq_animal in animal_ids:\n",
    "    \n",
    "\n",
    "    ky_c = {}\n",
    "    # chunks\n",
    "    for ky in valid_chunks.keys():\n",
    "        if unq_animal in ky:\n",
    "            spk_keys = list(spike_dict.keys())\n",
    "            spk_keys = [x for x in spk_keys if ky.split('_chunk')[0] in x]\n",
    "            \n",
    "            if unq_animal not in avg_chunks:\n",
    "                avg_chunks[unq_animal] = {}\n",
    "\n",
    "            ky_c[ky] = 1\n",
    "            # tetrodes\n",
    "            for spk_ky in spk_keys:\n",
    "                spk_data = spike_dict[spk_ky]\n",
    "                # cells \n",
    "                for cell in spk_data:\n",
    "                    tet_cell_id = str(spk_ky.split('_tet')[-1]) + '_' + str(cell.cluster.cluster_label)\n",
    "                    spks_to_plot = cell.event_times\n",
    "                    spks_to_plot = spks_to_plot[spks_to_plot >= valid_chunks[ky]['chunk_time'][0]]\n",
    "                    spks_to_plot = spks_to_plot[spks_to_plot <= valid_chunks[ky]['chunk_time'][-1]]\n",
    "\n",
    "                    position_bins = np.arange(0, 129, 129/64)\n",
    "                    pos_bin_ct = np.zeros((64))\n",
    "                    for spk in spks_to_plot:\n",
    "                        closest_chunk_time = valid_chunks[ky]['chunk_time'][np.argmin(np.abs(valid_chunks[ky]['chunk_time'] - spk))]\n",
    "                        closest_chunk_idx = np.where(valid_chunks[ky]['chunk_time'] == closest_chunk_time)[0][0]\n",
    "                        closest_chunk_position = valid_chunks[ky]['chunk_x'][closest_chunk_idx]\n",
    "                        closest_position_bin = position_bins[np.argmin(np.abs(position_bins - closest_chunk_position))]\n",
    "                        closest_position_bin_idx = np.argmin(np.abs(position_bins - closest_chunk_position))\n",
    "                        pos_bin_ct[closest_position_bin_idx] += 1\n",
    "\n",
    "                    column_values = np.linspace(0,129,64)\n",
    "                    occ_map_raw = np.zeros((64))\n",
    "                    for i in range(0,len(valid_chunks[ky]['chunk_time'])):\n",
    "                        column_index = np.abs(column_values - valid_chunks[ky]['chunk_x'][i]).argmin()\n",
    "                        occ_map_raw[column_index] += valid_chunks[ky]['chunk_time'][i] - valid_chunks[ky]['chunk_time'][i-1]\n",
    "                        # kernlen = int(1*8)\n",
    "                        # std = int(0.2*kernlen)\n",
    "                        # occ_map_normalized = occ_map_raw / pos_t[-1]\n",
    "                        # occ_map_smoothed = cv2.filter2D(occ_map_normalized,-1,_gkern(kernlen,std))\n",
    "                        # kernel = np.ones((2,2))\n",
    "                        # occ_map_smoothed = occ_map_smoothed/max(occ_map_smoothed.flatten())\n",
    "\n",
    "                    # if len(spks_to_plot) != 0:\n",
    "                    #     # fr_map = pos_bin_ct / np.max(spks_to_plot)\n",
    "                    #     kernlen = int(3 * 8)\n",
    "                    #     std = int(0.2 * kernlen)\n",
    "                    #     fr_map = cv2.filter2D(fr_map, -1, _gkern(kernlen, std))\n",
    "                    #     fr_map = fr_map / np.max(fr_map)\n",
    "                    #     # fr_map = ndimage.gaussian_filter(fr_map, sigma=1)\n",
    "                    fr_map_raw = pos_bin_ct \n",
    "                    # / np.max(pos_bin_ct)\n",
    "\n",
    "                    # kernlen = int(1 * 8)\n",
    "                    # std = int(0.2 * kernlen)\n",
    "                    # pos_bin_ct = cv2.filter2D(pos_bin_ct, -1, _gkern(kernlen, std))\n",
    "                    # fr_map_smoothed = pos_bin_ct / np.max(pos_bin_ct)\n",
    "\n",
    "                    \n",
    "                    if tet_cell_id in avg_chunks[unq_animal].keys():\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['collection'] += fr_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['occ_map'] += occ_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['count'] += 1\n",
    "                        if valid_chunks[ky]['chunk_time'][-1] > avg_chunks[unq_animal][tet_cell_id]['T']:\n",
    "                            avg_chunks[unq_animal][tet_cell_id]['T'] = valid_chunks[ky]['chunk_time'][-1]\n",
    "                    else:\n",
    "                        avg_chunks[unq_animal][tet_cell_id] = {'collection': [], 'count': 0, 'occ_map': [], 'T':0}\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['occ_map'] = occ_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['collection'] = fr_map_raw\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['count'] += 1\n",
    "                        avg_chunks[unq_animal][tet_cell_id]['T'] = valid_chunks[ky]['chunk_time'][-1]\n",
    "                    \n",
    "\n",
    "                    # axt.plot(valid_chunks[ky]['chunk_time'], valid_chunks[ky]['chunk_x'], color='red', lw=0.5)\n",
    "                    t = valid_chunks[ky]['chunk_time']\n",
    "                    x = valid_chunks[ky]['chunk_x']\n",
    "                    speed = _speed1D(x, t)\n",
    "                    # speed = ndimage.gaussian_filter(speed, sigma=100)\n",
    "                    # speed = smooth_signal(speed, [2,5,10,25,50,100,200,250,400,500,1000,2000])\n",
    "\n",
    "                    # convert_to_nan = np.where(speed > 20)[0]\n",
    "                    # convert_to_nan2 = np.where(speed < 10)[0]\n",
    "                    # convert_to_nan = np.concatenate((convert_to_nan, convert_to_nan2))\n",
    "                    # # convert_to_nan = []\n",
    "                    # # print(convert_to_nan)\n",
    "                    # # t[convert_to_nan] = np.nan\n",
    "                    # # t = t[(speed <30) & (speed > 0)]\n",
    "                    # # valid_spike_times = spks_to_plot[]\n",
    "                    # # speed = speed[(speed < 30) & (speed > 0)]\n",
    "                    # speed[convert_to_nan] = np.nan                 \n",
    "                    # smoothed_speed = ndimage.gaussian_filter(speed, sigma=100)\n",
    "                    \n",
    "                    if unq_animal == \"Mouse3_session11_230530_151933_2\":\n",
    "                        # t[speed > 20] = 0\n",
    "                        speed[speed > 7] = 0\n",
    "\n",
    "                    binned_spikes = np.zeros((len(t)))\n",
    "                    for spk in spks_to_plot:\n",
    "                        closest_chunk_time = t[np.argmin(np.abs(t - spk))]\n",
    "                        closest_chunk_idx = np.where(t == closest_chunk_time)[0][0]\n",
    "                        binned_spikes[closest_chunk_idx] += 1\n",
    "\n",
    "                    unq_cell_plot_dict_key = unq_animal + '_' + str(spk_ky.split('_tet')[-1]) + '_' + str(cell.cluster.cluster_label)\n",
    "                    if unq_cell_plot_dict_key not in unq_cell_plot_dict.keys():\n",
    "                        fig = plt.figure(figsize=(12, 3))\n",
    "                        ax = plt.subplot(1,1,1)\n",
    "                        axt = ax.twinx()\n",
    "                        axblank = ax.twinx()\n",
    "                        ttle = unq_animal + ' tetrode ' + str(spk_ky.split('_tet')[-1]) + ' cell ' + str(cell.cluster.cluster_label)\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key] = {'fig': fig, 'ax': ax, 'axt': axt, 'axblank': axblank, 'ttle': ttle}\n",
    "\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key]['binned_spikes'] = binned_spikes\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key]['t'] = t\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key]['speed'] = speed\n",
    "\n",
    "                    else:\n",
    "                        fig = unq_cell_plot_dict[unq_cell_plot_dict_key]['fig']\n",
    "                        ax = unq_cell_plot_dict[unq_cell_plot_dict_key]['ax']\n",
    "                        axt = unq_cell_plot_dict[unq_cell_plot_dict_key]['axt']\n",
    "                        axblank = unq_cell_plot_dict[unq_cell_plot_dict_key]['axblank']\n",
    "                        ttle = unq_cell_plot_dict[unq_cell_plot_dict_key]['ttle']\n",
    "\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key]['binned_spikes']= np.hstack((unq_cell_plot_dict[unq_cell_plot_dict_key]['binned_spikes'], binned_spikes))\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key]['t'] = np.hstack((unq_cell_plot_dict[unq_cell_plot_dict_key]['t'], t))\n",
    "                        unq_cell_plot_dict[unq_cell_plot_dict_key]['speed'] = np.hstack((unq_cell_plot_dict[unq_cell_plot_dict_key]['speed'], speed))\n",
    "\n",
    "                    # speed_smoothed = ndimage.gaussian_filter(speed, sigma=200)\n",
    "                    l1 = axt.plot(t, speed, color='red', lw=2, alpha=0.7, label='Speed')\n",
    "                    unq_cell_plot_dict[unq_cell_plot_dict_key]['l1'] = l1\n",
    "                    # axblank.plot(spks_to_plot, np.ones(len(spks_to_plot)) * ky_c[ky], 'ko', markersize=1)\n",
    "                    # hide y-axis\n",
    "                    axblank.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "                    ky_c[ky] += 1\n",
    "\n",
    "for ky in unq_cell_plot_dict:\n",
    "    ax = unq_cell_plot_dict[ky]['ax']\n",
    "    axt = unq_cell_plot_dict[ky]['axt']\n",
    "    fig = unq_cell_plot_dict[ky]['fig']\n",
    "    ttle = unq_cell_plot_dict[ky]['ttle']\n",
    "    binned_spikes = unq_cell_plot_dict[ky]['binned_spikes']\n",
    "    t = unq_cell_plot_dict[ky]['t']\n",
    "    speed = unq_cell_plot_dict[ky]['speed']\n",
    "    l1 = unq_cell_plot_dict[ky]['l1']\n",
    "\n",
    "    smoothed = ndimage.gaussian_filter(binned_spikes, sigma=100)\n",
    "    smoothed = smoothed / (t[1] - t[0])\n",
    "    correlation = pearsonr(speed, smoothed)\n",
    "    # correlation = pearsonr(speed_smoothed, smoothed)\n",
    "    l2 = ax.plot(t, smoothed, color='black', lw=2, alpha=1, label='Firing Rate')\n",
    "\n",
    "    lns = l2 + l1\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax.legend(lns, labs, loc='upper left')\n",
    "\n",
    "    ax.set_title(ttle + ' - Correlation: ' + str(correlation[0]))\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    axt.set_ylabel('Speed (cm/s)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_signal(signal, window_sizes):\n",
    "    smoothed_signal = np.zeros_like(signal, dtype=np.float64)\n",
    "    for window_size in window_sizes:\n",
    "        half_window = window_size // 2\n",
    "        for i in range(len(signal)):\n",
    "            start = max(0, i - half_window)\n",
    "            end = min(len(signal), i + half_window + 1)\n",
    "            mn = np.nanmean(signal[start:end])\n",
    "            smoothed_signal[i] += mn\n",
    "        smoothed_signal /= len(window_sizes)\n",
    "    return smoothed_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(smooth_signal(speed, np.arange(1, 1000, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "\n",
    "# make cmap based on value in ses_cts\n",
    "cmp = plt.get_cmap('jet')\n",
    "norm = plt.Normalize(vmin=0, vmax=max(ses_cts))\n",
    "\n",
    "c = 0\n",
    "for spike in spikes:\n",
    "    plt.scatter(spike,np.ones(len(spike))*c,s=1, color=cmp(norm(ses_cts[c])))\n",
    "    c += 1\n",
    "\n",
    "plt.ylabel('Cell #')\n",
    "plt.xlim(0,180)\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.title('Raster of all cells in all sessions')\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# make cmap based on value in ses_cts\n",
    "cmp = plt.get_cmap('jet')\n",
    "norm = plt.Normalize(vmin=0, vmax=max(ses_cts))\n",
    "fig = plt.figure(figsize=(8,1))\n",
    "\n",
    "c = 0\n",
    "prev = None\n",
    "for spike in spikes:\n",
    "    if ses_cts[c] != prev and prev is not None:\n",
    "        fig = plt.figure(figsize=(8,1))\n",
    "\n",
    "    plt.scatter(spike,np.ones(len(spike))*c,s=1, color=cmp(norm(ses_cts[c])))\n",
    "    if c != len(ses_cts)-1:\n",
    "        prev = ses_cts[c]\n",
    "\n",
    "        if ses_cts[c+1] != prev:\n",
    "            # plt.title('Session {}'.format(prev))\n",
    "            plt.title(ses_names[prev])\n",
    "            plt.ylabel('Cell #')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.show()\n",
    "            fig.tight_layout()\n",
    "        c += 1\n",
    "\n",
    "# plt.title('Session {}'.format(prev))\n",
    "plt.title(ses_names[prev])\n",
    "plt.ylabel('Cell #')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap1_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\VR_test_data\\10-2-23_lap\\lap1\\position.txt\"\n",
    "lap1_data = pd.read_csv(lap1_path, sep='\\t', header=None)\n",
    "lap1_data = lap1_data[0].str.split(';', expand=True)  \n",
    "lap1_data = lap1_data[~lap1_data[0].str.contains('POSITION')]\n",
    "lap1_data.columns = ['time', 'x', 'y']\n",
    "lap1_data = lap1_data.apply(pd.to_numeric)\n",
    "\n",
    "lap2_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\VR_test_data\\10-2-23_lap\\lap2\\position.txt\"\n",
    "lap2_data = pd.read_csv(lap2_path, sep='\\t', header=None)\n",
    "lap2_data = lap2_data[0].str.split(';', expand=True)\n",
    "lap2_data = lap2_data[~lap2_data[0].str.contains('POSITION')]\n",
    "lap2_data.columns = ['time', 'x', 'y']\n",
    "lap2_data = lap2_data.apply(pd.to_numeric)\n",
    "\n",
    "lap3_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\VR_test_data\\10-2-23_lap\\lap3\\position.txt\"\n",
    "lap3_data = pd.read_csv(lap3_path, sep='\\t', header=None)\n",
    "lap3_data = lap3_data[0].str.split(';', expand=True)\n",
    "lap3_data = lap3_data[~lap3_data[0].str.contains('POSITION')]\n",
    "lap3_data.columns = ['time', 'x', 'y']\n",
    "lap3_data = lap3_data.apply(pd.to_numeric)\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "\n",
    "ax1 = plt.subplot(1,3,1)\n",
    "ax1.plot(lap1_data['time'], lap1_data['x'])\n",
    "ax2 = plt.subplot(1,3,2)\n",
    "ax2.plot(lap2_data['time'], lap2_data['x'])\n",
    "ax3 = plt.subplot(1,3,3)\n",
    "ax3.plot(lap3_data['time'], lap3_data['x'])\n",
    "\n",
    "ax1.set_title('Lap 1')\n",
    "ax2.set_title('Lap 2')\n",
    "ax3.set_title('Lap 3')\n",
    "\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax3.set_xlabel('Time (s)')\n",
    "\n",
    "ax1.set_ylabel('X')\n",
    "ax2.set_ylabel('X')\n",
    "ax3.set_ylabel('X')\n",
    "\n",
    "fig.suptitle('X vs Time')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "\n",
    "ax1 = plt.subplot(1,3,1)\n",
    "ax1.plot(lap1_data['x'])\n",
    "ax2 = plt.subplot(1,3,2)\n",
    "ax2.plot(lap2_data['x'])\n",
    "ax3 = plt.subplot(1,3,3)\n",
    "ax3.plot(lap3_data['x'])\n",
    "\n",
    "ax1.set_title('Lap 1')\n",
    "ax2.set_title('Lap 2')\n",
    "ax3.set_title('Lap 3')\n",
    "\n",
    "ax1.set_xlabel('Index')\n",
    "ax2.set_xlabel('Index')\n",
    "ax3.set_xlabel('Index')\n",
    "\n",
    "ax1.set_ylabel('X')\n",
    "ax2.set_ylabel('X')\n",
    "ax3.set_ylabel('X')\n",
    "\n",
    "fig.suptitle('X vs Index')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lap_data in [lap1_data, lap2_data, lap3_data]:\n",
    "\n",
    "    # track_lap = np.zeros(lap_data['x'].shape)\n",
    "    # track_lap[lap_data['x'] >= 124] = 1\n",
    "\n",
    "    # check where change in time is greater than 1 second\n",
    "    lap_time_diff = np.diff(lap_data['time'])\n",
    "    idx_t = np.where(lap_time_diff <= -1)[0]\n",
    "    idx_t = idx_t[-1] + 1\n",
    "\n",
    "    # # # look for change from 0 to 1 and 1 to 0\n",
    "    lap_diff = np.diff(lap_data['x'])\n",
    "    idx = np.where(lap_diff <= -20 )[0]\n",
    "    if len(idx) > 0:\n",
    "        idx = idx[-1] + 1\n",
    "\n",
    "        idx_use = np.max([idx, idx_t])\n",
    "    else:\n",
    "        idx_use = idx_t\n",
    "\n",
    "    to_plot_x = lap_data['x'][idx_use:].to_numpy()\n",
    "    # to_plot_x -= to_plot_x[0]\n",
    "    to_plot_t = lap_data['time'][idx_use:].to_numpy()\n",
    "    # to_plot_t -= to_plot_t[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(8,3))\n",
    "    plt.plot(to_plot_t, to_plot_x)\n",
    "    plt.title('X vs Time')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('X position')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lap1_data['x'] >= 124)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPRISM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
